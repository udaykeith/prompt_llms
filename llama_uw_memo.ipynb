{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d43a484f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.callbacks.manager import CallbackManager\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "from langchain.llms import Ollama\n",
    "from langchain import PromptTemplate\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d1201a6b-ea7d-40ac-bb68-1fb0cf7a66c7",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'transformers'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pipeline\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'transformers'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c2eb3da0-bd4d-4a60-9554-bb1ab9949f25",
   "metadata": {},
   "source": [
    "## Theoretical considerations to Use-case\n",
    "- Is this an RAG/document answering or a summarization task?\n",
    "- If a summarization task, encoder-decoder-style models are typically used in generative tasks where the output heavily relies on the input.\n",
    "- For text-generation tasks, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5337f819",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "llm = Ollama(\n",
    "    model=\"llama2\",\n",
    "    repeat_last_n=10,\n",
    "    temperature=0.1,\n",
    "    repeat_penalty = 1.0,\n",
    "    top_k= 20,\n",
    "    callback_manager=CallbackManager([StreamingStdOutCallbackHandler()])\n",
    ")\n",
    "                                      \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4325456f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n<s>[INST] <<SYS>>\\n{{ system_prompt }}\\n<</SYS>>\\n{{ user_message }} [/INST]\\n'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "<s>[INST] <<SYS>>\n",
    "{{ system_prompt }}\n",
    "<</SYS>>\n",
    "{{ user_message }} [/INST]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fabd63ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "B_INST, E_INST = \"<s>[INST]\", \"[/INST]\"\n",
    "B_SYS, E_SYS = \"<<SYS>>\\n\", \"\\n<</SYS>>\\n\\n\"\n",
    "\n",
    "loader = PyPDFLoader(\"/Users/udaykeith/Downloads/ge_2023_Q3_10q.pdf\")\n",
    "pages = loader.load_and_split()\n",
    "\n",
    "example_description = \"\"\"\n",
    "Daktronics, Inc. (DAKT) is publicly traded manufacturer of electronic scoreboards, programmable display systems and large screen video displays for sporting, commercial, and transportation applications.  DAKT does business worldwide and is headquartered in Brookings, SD.  The company was originally founded in 1968 by Drs. Aelred Kurtenback and Duane Sander.  Today the company employs about 2,500 people globally.  \n",
    " \n",
    "DAKT's five business segments include:  Commercial, Live Events, High School Park and Rec, Transportation, and International. \"\"\"\n",
    "DEFAULT_SYSTEM_PROMPT = \"\"\"\\\n",
    "Your task is to provide a summary of a company, given only its financial statement.\n",
    "You will not provide any additional notes or disclaimers and limit the summary to only two paragraphs, nothing more. You will only use information given in the financial statement. Do repeat yourself or even refer to yourself.\n",
    "\"\"\"\n",
    "instruction = \"Given the financials statements the forward slashes, write a summary for the company General Electric //{pages[4]}//\"\n",
    "\n",
    "SYSTEM_PROMPT = B_SYS + DEFAULT_SYSTEM_PROMPT + E_SYS + instruction\n",
    "\n",
    "def get_prompt(instruction):\n",
    "    prompt_template =  B_INST + SYSTEM_PROMPT + instruction + E_INST\n",
    "    return prompt_template\n",
    "prompt_1 = get_prompt(SYSTEM_PROMPT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e91b5250",
   "metadata": {},
   "outputs": [],
   "source": [
    "ge = pages[4].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e44d9e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "p1 =  \"\"\"Write a concise summary of the main ideas in article below in bullet-points. Don't repeat ideas. article: {BODY}\"\"\".format(BODY=ge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "1344df63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on Ollama in module langchain_community.llms.ollama object:\n",
      "\n",
      "class Ollama(langchain_core.language_models.llms.BaseLLM, _OllamaCommon)\n",
      " |  Ollama(*, name: Optional[str] = None, base_url: str = 'http://localhost:11434', model: str = 'llama2', mirostat: Optional[int] = None, mirostat_eta: Optional[float] = None, mirostat_tau: Optional[float] = None, num_ctx: Optional[int] = None, num_gpu: Optional[int] = None, num_thread: Optional[int] = None, repeat_last_n: Optional[int] = None, repeat_penalty: Optional[float] = None, temperature: Optional[float] = None, stop: Optional[List[str]] = None, tfs_z: Optional[float] = None, top_k: Optional[int] = None, top_p: Optional[int] = None, system: Optional[str] = None, template: Optional[str] = None, format: Optional[str] = None, timeout: Optional[int] = None, cache: Optional[bool] = None, verbose: bool = None, callbacks: Union[List[langchain_core.callbacks.base.BaseCallbackHandler], langchain_core.callbacks.base.BaseCallbackManager, NoneType] = None, callback_manager: Optional[langchain_core.callbacks.base.BaseCallbackManager] = None, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None) -> None\n",
      " |  \n",
      " |  Ollama locally runs large language models.\n",
      " |  \n",
      " |  To use, follow the instructions at https://ollama.ai/.\n",
      " |  \n",
      " |  Example:\n",
      " |      .. code-block:: python\n",
      " |  \n",
      " |          from langchain_community.llms import Ollama\n",
      " |          ollama = Ollama(model=\"llama2\")\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      Ollama\n",
      " |      langchain_core.language_models.llms.BaseLLM\n",
      " |      _OllamaCommon\n",
      " |      langchain_core.language_models.base.BaseLanguageModel\n",
      " |      langchain_core.runnables.base.RunnableSerializable\n",
      " |      langchain_core.load.serializable.Serializable\n",
      " |      pydantic.v1.main.BaseModel\n",
      " |      pydantic.v1.utils.Representation\n",
      " |      langchain_core.runnables.base.Runnable\n",
      " |      typing.Generic\n",
      " |      abc.ABC\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Static methods defined here:\n",
      " |  \n",
      " |  __json_encoder__ = pydantic_encoder(obj: Any) -> Any\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  Config = <class 'langchain_community.llms.ollama.Ollama.Config'>\n",
      " |      Configuration for this pydantic object.\n",
      " |  \n",
      " |  \n",
      " |  __abstractmethods__ = frozenset()\n",
      " |  \n",
      " |  __annotations__ = {}\n",
      " |  \n",
      " |  __class_vars__ = set()\n",
      " |  \n",
      " |  __config__ = <class 'pydantic.v1.config.Config'>\n",
      " |  \n",
      " |  __custom_root_type__ = False\n",
      " |  \n",
      " |  __exclude_fields__ = {'callback_manager': True, 'callbacks': True, 'me...\n",
      " |  \n",
      " |  __fields__ = {'base_url': ModelField(name='base_url', type=str, requir...\n",
      " |  \n",
      " |  __hash__ = None\n",
      " |  \n",
      " |  __include_fields__ = None\n",
      " |  \n",
      " |  __parameters__ = ()\n",
      " |  \n",
      " |  __post_root_validators__ = [(False, <function BaseLLM.raise_deprecatio...\n",
      " |  \n",
      " |  __pre_root_validators__ = []\n",
      " |  \n",
      " |  __private_attributes__ = {'_lc_kwargs': ModelPrivateAttr(default=Pydan...\n",
      " |  \n",
      " |  __schema_cache__ = {}\n",
      " |  \n",
      " |  __signature__ = <Signature (*, name: Optional[str] = None, base_...tad...\n",
      " |  \n",
      " |  __validators__ = {'verbose': [<pydantic.v1.class_validators.Validator ...\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from langchain_core.language_models.llms.BaseLLM:\n",
      " |  \n",
      " |  __call__(self, prompt: 'str', stop: 'Optional[List[str]]' = None, callbacks: 'Callbacks' = None, *, tags: 'Optional[List[str]]' = None, metadata: 'Optional[Dict[str, Any]]' = None, **kwargs: 'Any') -> 'str'\n",
      " |      Check Cache and run the LLM on the given prompt and input.\n",
      " |  \n",
      " |  __str__(self) -> 'str'\n",
      " |      Get a string representation of the object for printing.\n",
      " |  \n",
      " |  async abatch(self, inputs: 'List[LanguageModelInput]', config: 'Optional[Union[RunnableConfig, List[RunnableConfig]]]' = None, *, return_exceptions: 'bool' = False, **kwargs: 'Any') -> 'List[str]'\n",
      " |      Default implementation runs ainvoke in parallel using asyncio.gather.\n",
      " |      \n",
      " |      The default implementation of batch works well for IO bound runnables.\n",
      " |      \n",
      " |      Subclasses should override this method if they can batch more efficiently;\n",
      " |      e.g., if the underlying runnable uses an API which supports a batch mode.\n",
      " |  \n",
      " |  async agenerate(self, prompts: 'List[str]', stop: 'Optional[List[str]]' = None, callbacks: 'Optional[Union[Callbacks, List[Callbacks]]]' = None, *, tags: 'Optional[Union[List[str], List[List[str]]]]' = None, metadata: 'Optional[Union[Dict[str, Any], List[Dict[str, Any]]]]' = None, run_name: 'Optional[Union[str, List[str]]]' = None, **kwargs: 'Any') -> 'LLMResult'\n",
      " |      Run the LLM on the given prompt and input.\n",
      " |  \n",
      " |  async agenerate_prompt(self, prompts: 'List[PromptValue]', stop: 'Optional[List[str]]' = None, callbacks: 'Optional[Union[Callbacks, List[Callbacks]]]' = None, **kwargs: 'Any') -> 'LLMResult'\n",
      " |      Asynchronously pass a sequence of prompts and return model generations.\n",
      " |      \n",
      " |      This method should make use of batched calls for models that expose a batched\n",
      " |      API.\n",
      " |      \n",
      " |      Use this method when you want to:\n",
      " |          1. take advantage of batched calls,\n",
      " |          2. need more output from the model than just the top generated value,\n",
      " |          3. are building chains that are agnostic to the underlying language model\n",
      " |              type (e.g., pure text completion models vs chat models).\n",
      " |      \n",
      " |      Args:\n",
      " |          prompts: List of PromptValues. A PromptValue is an object that can be\n",
      " |              converted to match the format of any language model (string for pure\n",
      " |              text generation models and BaseMessages for chat models).\n",
      " |          stop: Stop words to use when generating. Model output is cut off at the\n",
      " |              first occurrence of any of these substrings.\n",
      " |          callbacks: Callbacks to pass through. Used for executing additional\n",
      " |              functionality, such as logging or streaming, throughout generation.\n",
      " |          **kwargs: Arbitrary additional keyword arguments. These are usually passed\n",
      " |              to the model provider API call.\n",
      " |      \n",
      " |      Returns:\n",
      " |          An LLMResult, which contains a list of candidate Generations for each input\n",
      " |              prompt and additional model provider-specific output.\n",
      " |  \n",
      " |  async ainvoke(self, input: 'LanguageModelInput', config: 'Optional[RunnableConfig]' = None, *, stop: 'Optional[List[str]]' = None, **kwargs: 'Any') -> 'str'\n",
      " |      Default implementation of ainvoke, calls invoke from a thread.\n",
      " |      \n",
      " |      The default implementation allows usage of async code even if\n",
      " |      the runnable did not implement a native async version of invoke.\n",
      " |      \n",
      " |      Subclasses should override this method if they can run asynchronously.\n",
      " |  \n",
      " |  async apredict(self, text: 'str', *, stop: 'Optional[Sequence[str]]' = None, **kwargs: 'Any') -> 'str'\n",
      " |      Asynchronously pass a string to the model and return a string prediction.\n",
      " |      \n",
      " |      Use this method when calling pure text generation models and only the top\n",
      " |          candidate generation is needed.\n",
      " |      \n",
      " |      Args:\n",
      " |          text: String input to pass to the model.\n",
      " |          stop: Stop words to use when generating. Model output is cut off at the\n",
      " |              first occurrence of any of these substrings.\n",
      " |          **kwargs: Arbitrary additional keyword arguments. These are usually passed\n",
      " |              to the model provider API call.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Top model prediction as a string.\n",
      " |  \n",
      " |  async apredict_messages(self, messages: 'List[BaseMessage]', *, stop: 'Optional[Sequence[str]]' = None, **kwargs: 'Any') -> 'BaseMessage'\n",
      " |      Asynchronously pass messages to the model and return a message prediction.\n",
      " |      \n",
      " |      Use this method when calling chat models and only the top\n",
      " |          candidate generation is needed.\n",
      " |      \n",
      " |      Args:\n",
      " |          messages: A sequence of chat messages corresponding to a single model input.\n",
      " |          stop: Stop words to use when generating. Model output is cut off at the\n",
      " |              first occurrence of any of these substrings.\n",
      " |          **kwargs: Arbitrary additional keyword arguments. These are usually passed\n",
      " |              to the model provider API call.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Top model prediction as a message.\n",
      " |  \n",
      " |  async astream(self, input: 'LanguageModelInput', config: 'Optional[RunnableConfig]' = None, *, stop: 'Optional[List[str]]' = None, **kwargs: 'Any') -> 'AsyncIterator[str]'\n",
      " |      Default implementation of astream, which calls ainvoke.\n",
      " |      Subclasses should override this method if they support streaming output.\n",
      " |  \n",
      " |  batch(self, inputs: 'List[LanguageModelInput]', config: 'Optional[Union[RunnableConfig, List[RunnableConfig]]]' = None, *, return_exceptions: 'bool' = False, **kwargs: 'Any') -> 'List[str]'\n",
      " |      Default implementation runs invoke in parallel using a thread pool executor.\n",
      " |      \n",
      " |      The default implementation of batch works well for IO bound runnables.\n",
      " |      \n",
      " |      Subclasses should override this method if they can batch more efficiently;\n",
      " |      e.g., if the underlying runnable uses an API which supports a batch mode.\n",
      " |  \n",
      " |  dict(self, **kwargs: 'Any') -> 'Dict'\n",
      " |      Return a dictionary of the LLM.\n",
      " |  \n",
      " |  generate(self, prompts: 'List[str]', stop: 'Optional[List[str]]' = None, callbacks: 'Optional[Union[Callbacks, List[Callbacks]]]' = None, *, tags: 'Optional[Union[List[str], List[List[str]]]]' = None, metadata: 'Optional[Union[Dict[str, Any], List[Dict[str, Any]]]]' = None, run_name: 'Optional[Union[str, List[str]]]' = None, **kwargs: 'Any') -> 'LLMResult'\n",
      " |      Run the LLM on the given prompt and input.\n",
      " |  \n",
      " |  generate_prompt(self, prompts: 'List[PromptValue]', stop: 'Optional[List[str]]' = None, callbacks: 'Optional[Union[Callbacks, List[Callbacks]]]' = None, **kwargs: 'Any') -> 'LLMResult'\n",
      " |      Pass a sequence of prompts to the model and return model generations.\n",
      " |      \n",
      " |      This method should make use of batched calls for models that expose a batched\n",
      " |      API.\n",
      " |      \n",
      " |      Use this method when you want to:\n",
      " |          1. take advantage of batched calls,\n",
      " |          2. need more output from the model than just the top generated value,\n",
      " |          3. are building chains that are agnostic to the underlying language model\n",
      " |              type (e.g., pure text completion models vs chat models).\n",
      " |      \n",
      " |      Args:\n",
      " |          prompts: List of PromptValues. A PromptValue is an object that can be\n",
      " |              converted to match the format of any language model (string for pure\n",
      " |              text generation models and BaseMessages for chat models).\n",
      " |          stop: Stop words to use when generating. Model output is cut off at the\n",
      " |              first occurrence of any of these substrings.\n",
      " |          callbacks: Callbacks to pass through. Used for executing additional\n",
      " |              functionality, such as logging or streaming, throughout generation.\n",
      " |          **kwargs: Arbitrary additional keyword arguments. These are usually passed\n",
      " |              to the model provider API call.\n",
      " |      \n",
      " |      Returns:\n",
      " |          An LLMResult, which contains a list of candidate Generations for each input\n",
      " |              prompt and additional model provider-specific output.\n",
      " |  \n",
      " |  invoke(self, input: 'LanguageModelInput', config: 'Optional[RunnableConfig]' = None, *, stop: 'Optional[List[str]]' = None, **kwargs: 'Any') -> 'str'\n",
      " |      Transform a single input into an output. Override to implement.\n",
      " |      \n",
      " |      Args:\n",
      " |          input: The input to the runnable.\n",
      " |          config: A config to use when invoking the runnable.\n",
      " |             The config supports standard keys like 'tags', 'metadata' for tracing\n",
      " |             purposes, 'max_concurrency' for controlling how much work to do\n",
      " |             in parallel, and other keys. Please refer to the RunnableConfig\n",
      " |             for more details.\n",
      " |      \n",
      " |      Returns:\n",
      " |          The output of the runnable.\n",
      " |  \n",
      " |  predict(self, text: 'str', *, stop: 'Optional[Sequence[str]]' = None, **kwargs: 'Any') -> 'str'\n",
      " |      Pass a single string input to the model and return a string prediction.\n",
      " |      \n",
      " |       Use this method when passing in raw text. If you want to pass in specific\n",
      " |          types of chat messages, use predict_messages.\n",
      " |      \n",
      " |      Args:\n",
      " |          text: String input to pass to the model.\n",
      " |          stop: Stop words to use when generating. Model output is cut off at the\n",
      " |              first occurrence of any of these substrings.\n",
      " |          **kwargs: Arbitrary additional keyword arguments. These are usually passed\n",
      " |              to the model provider API call.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Top model prediction as a string.\n",
      " |  \n",
      " |  predict_messages(self, messages: 'List[BaseMessage]', *, stop: 'Optional[Sequence[str]]' = None, **kwargs: 'Any') -> 'BaseMessage'\n",
      " |      Pass a message sequence to the model and return a message prediction.\n",
      " |      \n",
      " |      Use this method when passing in chat messages. If you want to pass in raw text,\n",
      " |          use predict.\n",
      " |      \n",
      " |      Args:\n",
      " |          messages: A sequence of chat messages corresponding to a single model input.\n",
      " |          stop: Stop words to use when generating. Model output is cut off at the\n",
      " |              first occurrence of any of these substrings.\n",
      " |          **kwargs: Arbitrary additional keyword arguments. These are usually passed\n",
      " |              to the model provider API call.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Top model prediction as a message.\n",
      " |  \n",
      " |  save(self, file_path: 'Union[Path, str]') -> 'None'\n",
      " |      Save the LLM.\n",
      " |      \n",
      " |      Args:\n",
      " |          file_path: Path to file to save the LLM to.\n",
      " |      \n",
      " |      Example:\n",
      " |      .. code-block:: python\n",
      " |      \n",
      " |          llm.save(file_path=\"path/llm.yaml\")\n",
      " |  \n",
      " |  stream(self, input: 'LanguageModelInput', config: 'Optional[RunnableConfig]' = None, *, stop: 'Optional[List[str]]' = None, **kwargs: 'Any') -> 'Iterator[str]'\n",
      " |      Default implementation of stream, which calls invoke.\n",
      " |      Subclasses should override this method if they support streaming output.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from langchain_core.language_models.llms.BaseLLM:\n",
      " |  \n",
      " |  raise_deprecation(values: 'Dict') -> 'Dict' from pydantic.v1.main.ModelMetaclass\n",
      " |      Raise deprecation warning if callback_manager is used.\n",
      " |  \n",
      " |  set_verbose(verbose: 'Optional[bool]') -> 'bool' from pydantic.v1.main.ModelMetaclass\n",
      " |      If verbose is None, set it.\n",
      " |      \n",
      " |      This allows users to pass in None as verbose to access the global setting.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from langchain_core.language_models.llms.BaseLLM:\n",
      " |  \n",
      " |  OutputType\n",
      " |      Get the input type for this runnable.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes inherited from langchain_core.language_models.llms.BaseLLM:\n",
      " |  \n",
      " |  __orig_bases__ = (langchain_core.language_models.base.BaseLanguageMode...\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from langchain_core.language_models.base.BaseLanguageModel:\n",
      " |  \n",
      " |  get_num_tokens(self, text: 'str') -> 'int'\n",
      " |      Get the number of tokens present in the text.\n",
      " |      \n",
      " |      Useful for checking if an input will fit in a model's context window.\n",
      " |      \n",
      " |      Args:\n",
      " |          text: The string input to tokenize.\n",
      " |      \n",
      " |      Returns:\n",
      " |          The integer number of tokens in the text.\n",
      " |  \n",
      " |  get_num_tokens_from_messages(self, messages: 'List[BaseMessage]') -> 'int'\n",
      " |      Get the number of tokens in the messages.\n",
      " |      \n",
      " |      Useful for checking if an input will fit in a model's context window.\n",
      " |      \n",
      " |      Args:\n",
      " |          messages: The message inputs to tokenize.\n",
      " |      \n",
      " |      Returns:\n",
      " |          The sum of the number of tokens across the messages.\n",
      " |  \n",
      " |  get_token_ids(self, text: 'str') -> 'List[int]'\n",
      " |      Return the ordered ids of the tokens in a text.\n",
      " |      \n",
      " |      Args:\n",
      " |          text: The string input to tokenize.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A list of ids corresponding to the tokens in the text, in order they occur\n",
      " |              in the text.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from langchain_core.language_models.base.BaseLanguageModel:\n",
      " |  \n",
      " |  InputType\n",
      " |      Get the input type for this runnable.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from langchain_core.runnables.base.RunnableSerializable:\n",
      " |  \n",
      " |  configurable_alternatives(self, which: 'ConfigurableField', *, default_key: 'str' = 'default', prefix_keys: 'bool' = False, **kwargs: 'Union[Runnable[Input, Output], Callable[[], Runnable[Input, Output]]]') -> 'RunnableSerializable[Input, Output]'\n",
      " |  \n",
      " |  configurable_fields(self, **kwargs: 'AnyConfigurableField') -> 'RunnableSerializable[Input, Output]'\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from langchain_core.runnables.base.RunnableSerializable:\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from langchain_core.load.serializable.Serializable:\n",
      " |  \n",
      " |  __init__(self, **kwargs: Any) -> None\n",
      " |      Create a new model by parsing and validating input data from keyword arguments.\n",
      " |      \n",
      " |      Raises ValidationError if the input data cannot be parsed to form a valid model.\n",
      " |  \n",
      " |  __repr_args__(self) -> Any\n",
      " |      Returns the attributes to show in __str__, __repr__, and __pretty__ this is generally overridden.\n",
      " |      \n",
      " |      Can either return:\n",
      " |      * name - value pairs, e.g.: `[('foo_name', 'foo'), ('bar_name', ['b', 'a', 'r'])]`\n",
      " |      * or, just values, e.g.: `[(None, 'foo'), (None, ['b', 'a', 'r'])]`\n",
      " |  \n",
      " |  to_json(self) -> Union[langchain_core.load.serializable.SerializedConstructor, langchain_core.load.serializable.SerializedNotImplemented]\n",
      " |  \n",
      " |  to_json_not_implemented(self) -> langchain_core.load.serializable.SerializedNotImplemented\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from langchain_core.load.serializable.Serializable:\n",
      " |  \n",
      " |  get_lc_namespace() -> List[str] from pydantic.v1.main.ModelMetaclass\n",
      " |      Get the namespace of the langchain object.\n",
      " |      \n",
      " |      For example, if the class is `langchain.llms.openai.OpenAI`, then the\n",
      " |      namespace is [\"langchain\", \"llms\", \"openai\"]\n",
      " |  \n",
      " |  is_lc_serializable() -> bool from pydantic.v1.main.ModelMetaclass\n",
      " |      Is this class serializable?\n",
      " |  \n",
      " |  lc_id() -> List[str] from pydantic.v1.main.ModelMetaclass\n",
      " |      A unique identifier for this class for serialization purposes.\n",
      " |      \n",
      " |      The unique identifier is a list of strings that describes the path\n",
      " |      to the object.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from langchain_core.load.serializable.Serializable:\n",
      " |  \n",
      " |  lc_attributes\n",
      " |      List of attribute names that should be included in the serialized kwargs.\n",
      " |      \n",
      " |      These attributes must be accepted by the constructor.\n",
      " |  \n",
      " |  lc_secrets\n",
      " |      A map of constructor argument names to secret ids.\n",
      " |      \n",
      " |      For example,\n",
      " |          {\"openai_api_key\": \"OPENAI_API_KEY\"}\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from pydantic.v1.main.BaseModel:\n",
      " |  \n",
      " |  __eq__(self, other: Any) -> bool\n",
      " |      Return self==value.\n",
      " |  \n",
      " |  __getstate__(self) -> 'DictAny'\n",
      " |  \n",
      " |  __iter__(self) -> 'TupleGenerator'\n",
      " |      so `dict(model)` works\n",
      " |  \n",
      " |  __setattr__(self, name, value)\n",
      " |      Implement setattr(self, name, value).\n",
      " |  \n",
      " |  __setstate__(self, state: 'DictAny') -> None\n",
      " |  \n",
      " |  copy(self: 'Model', *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, update: Optional[ForwardRef('DictStrAny')] = None, deep: bool = False) -> 'Model'\n",
      " |      Duplicate a model, optionally choose which fields to include, exclude and change.\n",
      " |      \n",
      " |      :param include: fields to include in new model\n",
      " |      :param exclude: fields to exclude from new model, as with values this takes precedence over include\n",
      " |      :param update: values to change/add in the new model. Note: the data is not validated before creating\n",
      " |          the new model: you should trust this data\n",
      " |      :param deep: set to `True` to make a deep copy of the model\n",
      " |      :return: new model instance\n",
      " |  \n",
      " |  json(self, *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, by_alias: bool = False, skip_defaults: Optional[bool] = None, exclude_unset: bool = False, exclude_defaults: bool = False, exclude_none: bool = False, encoder: Optional[Callable[[Any], Any]] = None, models_as_dict: bool = True, **dumps_kwargs: Any) -> str\n",
      " |      Generate a JSON representation of the model, `include` and `exclude` arguments as per `dict()`.\n",
      " |      \n",
      " |      `encoder` is an optional function to supply as `default` to json.dumps(), other arguments as per `json.dumps()`.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from pydantic.v1.main.BaseModel:\n",
      " |  \n",
      " |  __get_validators__() -> 'CallableGenerator' from pydantic.v1.main.ModelMetaclass\n",
      " |  \n",
      " |  __try_update_forward_refs__(**localns: Any) -> None from pydantic.v1.main.ModelMetaclass\n",
      " |      Same as update_forward_refs but will not raise exception\n",
      " |      when forward references are not defined.\n",
      " |  \n",
      " |  construct(_fields_set: Optional[ForwardRef('SetStr')] = None, **values: Any) -> 'Model' from pydantic.v1.main.ModelMetaclass\n",
      " |      Creates a new model setting __dict__ and __fields_set__ from trusted or pre-validated data.\n",
      " |      Default values are respected, but no other validation is performed.\n",
      " |      Behaves as if `Config.extra = 'allow'` was set since it adds all passed values\n",
      " |  \n",
      " |  from_orm(obj: Any) -> 'Model' from pydantic.v1.main.ModelMetaclass\n",
      " |  \n",
      " |  parse_file(path: Union[str, pathlib.Path], *, content_type: str = None, encoding: str = 'utf8', proto: pydantic.v1.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from pydantic.v1.main.ModelMetaclass\n",
      " |  \n",
      " |  parse_obj(obj: Any) -> 'Model' from pydantic.v1.main.ModelMetaclass\n",
      " |  \n",
      " |  parse_raw(b: Union[str, bytes], *, content_type: str = None, encoding: str = 'utf8', proto: pydantic.v1.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from pydantic.v1.main.ModelMetaclass\n",
      " |  \n",
      " |  schema(by_alias: bool = True, ref_template: str = '#/definitions/{model}') -> 'DictStrAny' from pydantic.v1.main.ModelMetaclass\n",
      " |  \n",
      " |  schema_json(*, by_alias: bool = True, ref_template: str = '#/definitions/{model}', **dumps_kwargs: Any) -> str from pydantic.v1.main.ModelMetaclass\n",
      " |  \n",
      " |  update_forward_refs(**localns: Any) -> None from pydantic.v1.main.ModelMetaclass\n",
      " |      Try to update ForwardRefs on fields based on this Model, globalns and localns.\n",
      " |  \n",
      " |  validate(value: Any) -> 'Model' from pydantic.v1.main.ModelMetaclass\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from pydantic.v1.main.BaseModel:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __fields_set__\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from pydantic.v1.utils.Representation:\n",
      " |  \n",
      " |  __pretty__(self, fmt: Callable[[Any], Any], **kwargs: Any) -> Generator[Any, NoneType, NoneType]\n",
      " |      Used by devtools (https://python-devtools.helpmanual.io/) to provide a human readable representations of objects\n",
      " |  \n",
      " |  __repr__(self) -> str\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __repr_name__(self) -> str\n",
      " |      Name of the instance's class, used in __repr__.\n",
      " |  \n",
      " |  __repr_str__(self, join_str: str) -> str\n",
      " |  \n",
      " |  __rich_repr__(self) -> 'RichReprResult'\n",
      " |      Get fields for Rich library\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from langchain_core.runnables.base.Runnable:\n",
      " |  \n",
      " |  __or__(self, other: 'Union[Runnable[Any, Other], Callable[[Any], Other], Callable[[Iterator[Any]], Iterator[Other]], Mapping[str, Union[Runnable[Any, Other], Callable[[Any], Other], Any]]]') -> 'RunnableSerializable[Input, Other]'\n",
      " |      Compose this runnable with another object to create a RunnableSequence.\n",
      " |  \n",
      " |  __ror__(self, other: 'Union[Runnable[Other, Any], Callable[[Other], Any], Callable[[Iterator[Other]], Iterator[Any]], Mapping[str, Union[Runnable[Other, Any], Callable[[Other], Any], Any]]]') -> 'RunnableSerializable[Other, Output]'\n",
      " |      Compose this runnable with another object to create a RunnableSequence.\n",
      " |  \n",
      " |  assign(self, **kwargs: 'Union[Runnable[Dict[str, Any], Any], Callable[[Dict[str, Any]], Any], Mapping[str, Union[Runnable[Dict[str, Any], Any], Callable[[Dict[str, Any]], Any]]]]') -> 'RunnableSerializable[Any, Any]'\n",
      " |      Assigns new fields to the dict output of this runnable.\n",
      " |      Returns a new runnable.\n",
      " |  \n",
      " |  async astream_log(self, input: 'Any', config: 'Optional[RunnableConfig]' = None, *, diff: 'bool' = True, with_streamed_output_list: 'bool' = True, include_names: 'Optional[Sequence[str]]' = None, include_types: 'Optional[Sequence[str]]' = None, include_tags: 'Optional[Sequence[str]]' = None, exclude_names: 'Optional[Sequence[str]]' = None, exclude_types: 'Optional[Sequence[str]]' = None, exclude_tags: 'Optional[Sequence[str]]' = None, **kwargs: 'Optional[Any]') -> 'Union[AsyncIterator[RunLogPatch], AsyncIterator[RunLog]]'\n",
      " |      Stream all output from a runnable, as reported to the callback system.\n",
      " |      This includes all inner runs of LLMs, Retrievers, Tools, etc.\n",
      " |      \n",
      " |      Output is streamed as Log objects, which include a list of\n",
      " |      jsonpatch ops that describe how the state of the run has changed in each\n",
      " |      step, and the final state of the run.\n",
      " |      \n",
      " |      The jsonpatch ops can be applied in order to construct state.\n",
      " |      \n",
      " |      Args:\n",
      " |          input: The input to the runnable.\n",
      " |          config: The config to use for the runnable.\n",
      " |          diff: Whether to yield diffs between each step, or the current state.\n",
      " |          with_streamed_output_list: Whether to yield the streamed_output list.\n",
      " |          include_names: Only include logs with these names.\n",
      " |          include_types: Only include logs with these types.\n",
      " |          include_tags: Only include logs with these tags.\n",
      " |          exclude_names: Exclude logs with these names.\n",
      " |          exclude_types: Exclude logs with these types.\n",
      " |          exclude_tags: Exclude logs with these tags.\n",
      " |  \n",
      " |  async atransform(self, input: 'AsyncIterator[Input]', config: 'Optional[RunnableConfig]' = None, **kwargs: 'Optional[Any]') -> 'AsyncIterator[Output]'\n",
      " |      Default implementation of atransform, which buffers input and calls astream.\n",
      " |      Subclasses should override this method if they can start producing output while\n",
      " |      input is still being generated.\n",
      " |  \n",
      " |  bind(self, **kwargs: 'Any') -> 'Runnable[Input, Output]'\n",
      " |      Bind arguments to a Runnable, returning a new Runnable.\n",
      " |  \n",
      " |  config_schema(self, *, include: 'Optional[Sequence[str]]' = None) -> 'Type[BaseModel]'\n",
      " |      The type of config this runnable accepts specified as a pydantic model.\n",
      " |      \n",
      " |      To mark a field as configurable, see the `configurable_fields`\n",
      " |      and `configurable_alternatives` methods.\n",
      " |      \n",
      " |      Args:\n",
      " |          include: A list of fields to include in the config schema.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A pydantic model that can be used to validate config.\n",
      " |  \n",
      " |  get_graph(self, config: 'Optional[RunnableConfig]' = None) -> 'Graph'\n",
      " |      Return a graph representation of this runnable.\n",
      " |  \n",
      " |  get_input_schema(self, config: 'Optional[RunnableConfig]' = None) -> 'Type[BaseModel]'\n",
      " |      Get a pydantic model that can be used to validate input to the runnable.\n",
      " |      \n",
      " |      Runnables that leverage the configurable_fields and configurable_alternatives\n",
      " |      methods will have a dynamic input schema that depends on which\n",
      " |      configuration the runnable is invoked with.\n",
      " |      \n",
      " |      This method allows to get an input schema for a specific configuration.\n",
      " |      \n",
      " |      Args:\n",
      " |          config: A config to use when generating the schema.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A pydantic model that can be used to validate input.\n",
      " |  \n",
      " |  get_name(self, suffix: 'Optional[str]' = None, *, name: 'Optional[str]' = None) -> 'str'\n",
      " |      Get the name of the runnable.\n",
      " |  \n",
      " |  get_output_schema(self, config: 'Optional[RunnableConfig]' = None) -> 'Type[BaseModel]'\n",
      " |      Get a pydantic model that can be used to validate output to the runnable.\n",
      " |      \n",
      " |      Runnables that leverage the configurable_fields and configurable_alternatives\n",
      " |      methods will have a dynamic output schema that depends on which\n",
      " |      configuration the runnable is invoked with.\n",
      " |      \n",
      " |      This method allows to get an output schema for a specific configuration.\n",
      " |      \n",
      " |      Args:\n",
      " |          config: A config to use when generating the schema.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A pydantic model that can be used to validate output.\n",
      " |  \n",
      " |  map(self) -> 'Runnable[List[Input], List[Output]]'\n",
      " |      Return a new Runnable that maps a list of inputs to a list of outputs,\n",
      " |      by calling invoke() with each input.\n",
      " |  \n",
      " |  pick(self, keys: 'Union[str, List[str]]') -> 'RunnableSerializable[Any, Any]'\n",
      " |      Pick keys from the dict output of this runnable.\n",
      " |      Returns a new runnable.\n",
      " |  \n",
      " |  pipe(self, *others: 'Union[Runnable[Any, Other], Callable[[Any], Other]]', name: 'Optional[str]' = None) -> 'RunnableSerializable[Input, Other]'\n",
      " |      Compose this runnable with another object to create a RunnableSequence.\n",
      " |  \n",
      " |  transform(self, input: 'Iterator[Input]', config: 'Optional[RunnableConfig]' = None, **kwargs: 'Optional[Any]') -> 'Iterator[Output]'\n",
      " |      Default implementation of transform, which buffers input and then calls stream.\n",
      " |      Subclasses should override this method if they can start producing output while\n",
      " |      input is still being generated.\n",
      " |  \n",
      " |  with_config(self, config: 'Optional[RunnableConfig]' = None, **kwargs: 'Any') -> 'Runnable[Input, Output]'\n",
      " |      Bind config to a Runnable, returning a new Runnable.\n",
      " |  \n",
      " |  with_fallbacks(self, fallbacks: 'Sequence[Runnable[Input, Output]]', *, exceptions_to_handle: 'Tuple[Type[BaseException], ...]' = (<class 'Exception'>,)) -> 'RunnableWithFallbacksT[Input, Output]'\n",
      " |      Add fallbacks to a runnable, returning a new Runnable.\n",
      " |      \n",
      " |      Args:\n",
      " |          fallbacks: A sequence of runnables to try if the original runnable fails.\n",
      " |          exceptions_to_handle: A tuple of exception types to handle.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A new Runnable that will try the original runnable, and then each\n",
      " |          fallback in order, upon failures.\n",
      " |  \n",
      " |  with_listeners(self, *, on_start: 'Optional[Listener]' = None, on_end: 'Optional[Listener]' = None, on_error: 'Optional[Listener]' = None) -> 'Runnable[Input, Output]'\n",
      " |      Bind lifecycle listeners to a Runnable, returning a new Runnable.\n",
      " |      \n",
      " |      on_start: Called before the runnable starts running, with the Run object.\n",
      " |      on_end: Called after the runnable finishes running, with the Run object.\n",
      " |      on_error: Called if the runnable throws an error, with the Run object.\n",
      " |      \n",
      " |      The Run object contains information about the run, including its id,\n",
      " |      type, input, output, error, start_time, end_time, and any tags or metadata\n",
      " |      added to the run.\n",
      " |  \n",
      " |  with_retry(self, *, retry_if_exception_type: 'Tuple[Type[BaseException], ...]' = (<class 'Exception'>,), wait_exponential_jitter: 'bool' = True, stop_after_attempt: 'int' = 3) -> 'Runnable[Input, Output]'\n",
      " |      Create a new Runnable that retries the original runnable on exceptions.\n",
      " |      \n",
      " |      Args:\n",
      " |          retry_if_exception_type: A tuple of exception types to retry on\n",
      " |          wait_exponential_jitter: Whether to add jitter to the wait time\n",
      " |                                   between retries\n",
      " |          stop_after_attempt: The maximum number of attempts to make before giving up\n",
      " |      \n",
      " |      Returns:\n",
      " |          A new Runnable that retries the original runnable on exceptions.\n",
      " |  \n",
      " |  with_types(self, *, input_type: 'Optional[Type[Input]]' = None, output_type: 'Optional[Type[Output]]' = None) -> 'Runnable[Input, Output]'\n",
      " |      Bind input and output types to a Runnable, returning a new Runnable.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from langchain_core.runnables.base.Runnable:\n",
      " |  \n",
      " |  config_specs\n",
      " |      List configurable fields for this runnable.\n",
      " |  \n",
      " |  input_schema\n",
      " |      The type of input this runnable accepts specified as a pydantic model.\n",
      " |  \n",
      " |  output_schema\n",
      " |      The type of output this runnable produces specified as a pydantic model.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes inherited from langchain_core.runnables.base.Runnable:\n",
      " |  \n",
      " |  name = None\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from typing.Generic:\n",
      " |  \n",
      " |  __class_getitem__(params) from pydantic.v1.main.ModelMetaclass\n",
      " |  \n",
      " |  __init_subclass__(*args, **kwargs) from pydantic.v1.main.ModelMetaclass\n",
      " |      This method is called when a class is subclassed.\n",
      " |      \n",
      " |      The default implementation does nothing. It may be\n",
      " |      overridden to extend subclasses.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac60ead2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Your task is to generate a short summary of a product \\\n",
    "review of an application that is available on playstore.\n",
    " \n",
    "Summarize the review below, delimited by triple \n",
    "backticks, in at most 30 words. \n",
    " \n",
    "Review: ```{prod_review}```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "95101d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "p4 = \"\"\"<s>[INST] <<SYS>>\n",
    "You are an underwriter that is reviewing a company. At this point in your analysis, your analyses focues on the financial risk of the company.\n",
    "<</SYS>>\n",
    "You task is to write a summary of the company based only on the artcle below delmited by triple backticks. Limit the summary to a maximum of 250 words and a minumum of \n",
    "200 words. You must refer to the recent financials in your summary. article: ```{BODY}```\n",
    "\"\"\".format(BODY=ge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "e2059c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"You are an underwriter that is reviewing a company. You task is to provide a summary of the company\n",
    "based only on the context below delmited by triple backticks, in at most 220 words however using a minumum of 200 words. You must refer to the recent financials in your summary.\n",
    "\n",
    "context : ```ABOUT GENERAL ELECTRIC.  General Electric Company (General Electric, GE or the Company) is a high-tech industrial \\ncompany that operates worldwide through its three segments, Aerospace, Renewable Energy, and Power. Our products include \\ncommercial and defense aircraft engines and systems; wind and other renewable energy generation equipment and grid solutions; and \\ngas, steam, nuclear and other power generation equipment. We have significant global installed bases of equipment across these \\nsectors, and services to support these products are also an important part of our business alongside new equipment sales. \\nWe previously announced a strategic plan to form three industry-leading, global, investment-grade public companies from (i) our \\nAerospace business, which we plan to refer to as GE Aerospace, (ii) our portfolio of energy businesses, including our Renewable \\nEnergy and Power businesses, which we plan to combine and refer to as GE Vernova, and (iii) our former HealthCare business. For \\npurposes of this report, we refer to our reporting segments as Aerospace, Renewable Energy and Power. The composition of these \\nreporting segments is unchanged. On January 3, 2023, we completed the separation of the HealthCare business from GE through the \\nspin-off of GE HealthCare Technologies Inc. (GE HealthCare). See Notes 2 and 3 for further information. The historical results of GE \\nHealthCare and certain assets and liabilities included in the spin-off are now reported in GE's consolidated financial statements as \\ndiscontinued operations. Additionally, on January 1, 2023, we adopted Accounting Standards Update No. 2018-12, Financial Services – \\nInsurance (Topic 944): Targeted Improvements to the Accounting for Long-Duration Contracts . See Note 13 for further information. \\nGE’s Internet address at www.ge.com, Investor Relations website at www.ge.com/investor-relations and our corporate blog at \\nwww.gereports.com, as well as GE’s LinkedIn and other social media accounts, including @GE_Reports, contain a significant amount \\nof information about GE, including financial and other information for investors. GE encourages investors to visit these websites from \\ntime to time, as information is updated and new information is posted.  \\nMANAGEMENT’S DISCUSSION AND ANALYSIS OF FINANCIAL CONDITION AND RESULTS OF \\nOPERATIONS (MD&A). The consolidated financial statements of General Electric Company are prepared in conformity with U.S. \\ngenerally accepted accounting principles (GAAP). Unless otherwise noted, tables are presented in U.S. dollars in millions. Certain \\ncolumns and rows within tables may not add due to the use of rounded numbers. Percentages presented in this report are calculated \\nfrom the underlying numbers in millions. Discussions throughout this MD&A are based on continuing operations unless otherwise noted. \\nThe MD&A should be read in conjunction with the Financial Statements and Notes to the consolidated financial statements. \\nIn the accompanying analysis of financial information, we sometimes use information derived from consolidated financial data but not \\npresented in our financial statements prepared in accordance with GAAP. Certain of these data are considered “non-GAAP financial \\nmeasures” under SEC rules. See the Non-GAAP Financial Measures section for the reasons we use these non-GAAP financial \\nmeasures and the reconciliations to their most directly comparable GAAP financial measures.\\nCONSOLIDATED RESULTS  \\nTHIRD  QUARTER 2023  RESULTS. Total revenues were $17.3 billion , up $2.9 billion  for the quarter, driven primarily by increases at \\nAerospace and Renewable Energy.\\nContinuing earnings (loss) per share was $0.08 . Excluding the results from our run-off Insurance business, gains (losses) on retained \\nand sold ownership interests, non-operating benefit costs, interest and other financial charges, separation co\n",
    "\n",
    "Summary: \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "74ea6cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"context\"],\n",
    "    template=template,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7a825415",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are the main ideas from the article:\n",
      "\n",
      "1. General Electric Company (GE) is a high-tech industrial company that operates globally through its three segments: Aerospace, Renewable Energy, and Power.\n",
      "2. GE's products include commercial and defense aircraft engines and systems, wind and other renewable energy generation equipment, and gas, steam, nuclear, and other power generation equipment.\n",
      "3. GE has significant global installed bases of equipment across these sectors, and services to support these products are also an important part of its business.\n",
      "4. GE has announced a strategic plan to form three industry-leading, global, investment-grade public companies from its Aerospace, energy, and HealthCare businesses.\n",
      "5. The composition of GE's reporting segments is unchanged, and the historical results of GE HealthCare are now reported in GE's consolidated financial statements as discontinued operations.\n",
      "6. GE's Internet address, Investor Relations website, and corporate blog contain a significant amount of information about GE, including financial and other information for investors.\n",
      "7. The consolidated financial statements of General Electric Company are prepared in conformity with U.S. generally accepted accounting principles (GAAP).\n",
      "8. Certain columns and rows within tables may not add due to the use of rounded numbers, and percentages presented in this report are calculated from the underlying numbers in millions.\n",
      "9. The MD&A should be read in conjunction with the Financial Statements and Notes to the consolidated financial statements.\n",
      "10. GE uses non-GAAP financial measures, which are considered \"non-GAAP financial measures\" under SEC rules, to provide additional information regarding its financial performance."
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Here are the main ideas from the article:\\n\\n1. General Electric Company (GE) is a high-tech industrial company that operates globally through its three segments: Aerospace, Renewable Energy, and Power.\\n2. GE\\'s products include commercial and defense aircraft engines and systems, wind and other renewable energy generation equipment, and gas, steam, nuclear, and other power generation equipment.\\n3. GE has significant global installed bases of equipment across these sectors, and services to support these products are also an important part of its business.\\n4. GE has announced a strategic plan to form three industry-leading, global, investment-grade public companies from its Aerospace, energy, and HealthCare businesses.\\n5. The composition of GE\\'s reporting segments is unchanged, and the historical results of GE HealthCare are now reported in GE\\'s consolidated financial statements as discontinued operations.\\n6. GE\\'s Internet address, Investor Relations website, and corporate blog contain a significant amount of information about GE, including financial and other information for investors.\\n7. The consolidated financial statements of General Electric Company are prepared in conformity with U.S. generally accepted accounting principles (GAAP).\\n8. Certain columns and rows within tables may not add due to the use of rounded numbers, and percentages presented in this report are calculated from the underlying numbers in millions.\\n9. The MD&A should be read in conjunction with the Financial Statements and Notes to the consolidated financial statements.\\n10. GE uses non-GAAP financial measures, which are considered \"non-GAAP financial measures\" under SEC rules, to provide additional information regarding its financial performance.'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm(p1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "9edffd2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "292"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(response.split(\" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "01a84f61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "General Electric Company (GE) is a high-tech industrial company that operates globally across three segments: Aerospace, Renewable Energy, and Power. The company has a significant installed base of equipment across these sectors, and services to support these products, as well as new equipment sales. GE has announced a strategic plan to form three industry-leading, global, investment-grade public companies from its Aerospace, energy, and former HealthCare businesses. The company's historical results of GE HealthCare and certain assets and liabilities included in the spin-off are now reported in GE's consolidated financial statements as discontinued operations. GE has adopted Accounting Standards Update No. 2018-12, Financial Services – Insurance (Topic 944): Targeted Improvements to the Accounting for Long-Duration Contracts. The company's consolidated financial statements are prepared in conformity with US GAAP, and certain columns and rows within tables may not add due to the use of rounded numbers. Percentages presented in this report are calculated from the underlying numbers in millions. The MD&A should be read in conjunction with the Financial Statements and Notes to the consolidated financial statements. In the accompanying analysis of financial information, the company uses information derived from consolidated financial data but not presented in its financial statements prepared in accordance with GAAP. Certain of these data are considered \"non-GAAP financial measures\" under SEC rules. The company's total revenues were $17.3 billion for the third quarter of 2023, up $2.9 billion from the same period last year, driven primarily by increases at Aerospace and Renewable Energy. The company's continuing earnings (loss) per share was $0.08, excluding the results from its run-off Insurance business, gains (losses) on retained and sold ownership interests, non-operating benefit costs, interest, and other financial charges, separation costs, and other items, the company's earnings (loss) per share was $0.10."
     ]
    }
   ],
   "source": [
    "response = (llm(prompt.format(\n",
    "         query = \"\")\n",
    "     )\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a6094eef",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'pages'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m llm(\u001b[43mprompt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpages\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpage_content\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/Desktop/code/venvs/llama/lib/python3.10/site-packages/langchain_core/prompts/prompt.py:132\u001b[0m, in \u001b[0;36mPromptTemplate.format\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Format the prompt with the inputs.\u001b[39;00m\n\u001b[1;32m    118\u001b[0m \n\u001b[1;32m    119\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[38;5;124;03m        prompt.format(variable1=\"foo\")\u001b[39;00m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    131\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_merge_partial_and_user_variables(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 132\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDEFAULT_FORMATTER_MAPPING\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtemplate_format\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtemplate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.10/3.10.13_1/Frameworks/Python.framework/Versions/3.10/lib/python3.10/string.py:161\u001b[0m, in \u001b[0;36mFormatter.format\u001b[0;34m(self, format_string, *args, **kwargs)\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mformat\u001b[39m(\u001b[38;5;28mself\u001b[39m, format_string, \u001b[38;5;241m/\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 161\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvformat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mformat_string\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/code/venvs/llama/lib/python3.10/site-packages/langchain_core/utils/formatting.py:18\u001b[0m, in \u001b[0;36mStrictFormatter.vformat\u001b[0;34m(self, format_string, args, kwargs)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m     15\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo arguments should be provided, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     16\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124meverything should be passed as keyword arguments.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     17\u001b[0m     )\n\u001b[0;32m---> 18\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvformat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mformat_string\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.10/3.10.13_1/Frameworks/Python.framework/Versions/3.10/lib/python3.10/string.py:165\u001b[0m, in \u001b[0;36mFormatter.vformat\u001b[0;34m(self, format_string, args, kwargs)\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvformat\u001b[39m(\u001b[38;5;28mself\u001b[39m, format_string, args, kwargs):\n\u001b[1;32m    164\u001b[0m     used_args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n\u001b[0;32m--> 165\u001b[0m     result, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_vformat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mformat_string\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mused_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_unused_args(used_args, args, kwargs)\n\u001b[1;32m    167\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.10/3.10.13_1/Frameworks/Python.framework/Versions/3.10/lib/python3.10/string.py:205\u001b[0m, in \u001b[0;36mFormatter._vformat\u001b[0;34m(self, format_string, args, kwargs, used_args, recursion_depth, auto_arg_index)\u001b[0m\n\u001b[1;32m    201\u001b[0m     auto_arg_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    203\u001b[0m \u001b[38;5;66;03m# given the field_name, find the object it references\u001b[39;00m\n\u001b[1;32m    204\u001b[0m \u001b[38;5;66;03m#  and the argument it came from\u001b[39;00m\n\u001b[0;32m--> 205\u001b[0m obj, arg_used \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_field\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfield_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    206\u001b[0m used_args\u001b[38;5;241m.\u001b[39madd(arg_used)\n\u001b[1;32m    208\u001b[0m \u001b[38;5;66;03m# do any conversion on the resulting object\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.10/3.10.13_1/Frameworks/Python.framework/Versions/3.10/lib/python3.10/string.py:270\u001b[0m, in \u001b[0;36mFormatter.get_field\u001b[0;34m(self, field_name, args, kwargs)\u001b[0m\n\u001b[1;32m    267\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_field\u001b[39m(\u001b[38;5;28mself\u001b[39m, field_name, args, kwargs):\n\u001b[1;32m    268\u001b[0m     first, rest \u001b[38;5;241m=\u001b[39m _string\u001b[38;5;241m.\u001b[39mformatter_field_name_split(field_name)\n\u001b[0;32m--> 270\u001b[0m     obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfirst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    272\u001b[0m     \u001b[38;5;66;03m# loop through the rest of the field_name, doing\u001b[39;00m\n\u001b[1;32m    273\u001b[0m     \u001b[38;5;66;03m#  getattr or getitem as needed\u001b[39;00m\n\u001b[1;32m    274\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m is_attr, i \u001b[38;5;129;01min\u001b[39;00m rest:\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.10/3.10.13_1/Frameworks/Python.framework/Versions/3.10/lib/python3.10/string.py:227\u001b[0m, in \u001b[0;36mFormatter.get_value\u001b[0;34m(self, key, args, kwargs)\u001b[0m\n\u001b[1;32m    225\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m args[key]\n\u001b[1;32m    226\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 227\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mkwargs\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'pages'"
     ]
    }
   ],
   "source": [
    "llm(prompt.format(text=pages[4].page_content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "53acf558",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Thank you for your feedback! I'm glad you find the summary helpful. To ensure consistency in future summaries, I will follow this style exactly as you have requested. Please let me know if there's anything else I can do for you."
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\nThank you for your feedback! I'm glad you find the summary helpful. To ensure consistency in future summaries, I will follow this style exactly as you have requested. Please let me know if there's anything else I can do for you.\""
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm(\"This is perfect. For future summaries, follow this style exactly.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "cf9a173a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Microsoft is a multinational technology company that develops, manufactures, licenses, and supports a wide range of software products, services, and devices. The company was founded in 1975 by Bill Gates and Paul Allen, and is headquartered in Redmond, Washington. Microsoft is one of the largest and most successful technology companies in the world, with a diverse portfolio of products and services that include:\n",
      "\n",
      "* Operating systems: Microsoft produces the Windows operating system, which is used by millions of computers around the world. The company also offers other operating systems, such as Windows Server and Windows Embedded.\n",
      "* Productivity software: Microsoft is known for its productivity software, including Word, Excel, and PowerPoint. These applications are used by millions of people around the world for work, school, and personal projects.\n",
      "* Gaming: Microsoft owns Xbox, a popular gaming platform that includes the Xbox console, Xbox games, and Xbox Live online gaming service.\n",
      "* Cloud computing: Microsoft offers a range of cloud computing services, including Azure, a platform for building, deploying, and managing applications and services, and Office 365, a cloud-based version of its productivity software.\n",
      "* Artificial intelligence: Microsoft is a leader in the field of artificial intelligence, with a range of AI technologies and tools, including Azure Machine Learning, Azure Cognitive Services, and Microsoft Bot Framework.\n",
      "* Mixed reality: Microsoft is a pioneer in the field of mixed reality, with a range of products and services that enable users to experience virtual and augmented reality.\n",
      "* Devices: Microsoft produces a range of devices, including Surface laptops and tablets, Lumia smartphones, and HoloLens augmented reality headsets.\n",
      "* Enterprise software: Microsoft offers a range of enterprise software solutions, including Dynamics 365 for business management, Dynamics CRM for customer relationship management, and Azure DevOps for software development and delivery.\n",
      "* Online services: Microsoft offers a range of online services, including Bing search engine, MSN news and entertainment platform, and Skype communication platform.\n",
      "* Education: Microsoft offers a range of educational software and resources, including Microsoft Office Specialist, Microsoft Certified Educator, and Minecraft: Education Edition.\n",
      "* Healthcare: Microsoft offers a range of healthcare solutions, including Microsoft Healthcare, which provides a platform for healthcare providers to manage patient data and deliver personalized care.\n",
      "\n",
      "Overall, Microsoft is a diversified technology company with a wide range of products and services that cater to various industries and needs. The company has a strong track record of innovation and has played a significant role in shaping the technology industry over the past several decades."
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nMicrosoft is a multinational technology company that develops, manufactures, licenses, and supports a wide range of software products, services, and devices. The company was founded in 1975 by Bill Gates and Paul Allen, and is headquartered in Redmond, Washington. Microsoft is one of the largest and most successful technology companies in the world, with a diverse portfolio of products and services that include:\\n\\n* Operating systems: Microsoft produces the Windows operating system, which is used by millions of computers around the world. The company also offers other operating systems, such as Windows Server and Windows Embedded.\\n* Productivity software: Microsoft is known for its productivity software, including Word, Excel, and PowerPoint. These applications are used by millions of people around the world for work, school, and personal projects.\\n* Gaming: Microsoft owns Xbox, a popular gaming platform that includes the Xbox console, Xbox games, and Xbox Live online gaming service.\\n* Cloud computing: Microsoft offers a range of cloud computing services, including Azure, a platform for building, deploying, and managing applications and services, and Office 365, a cloud-based version of its productivity software.\\n* Artificial intelligence: Microsoft is a leader in the field of artificial intelligence, with a range of AI technologies and tools, including Azure Machine Learning, Azure Cognitive Services, and Microsoft Bot Framework.\\n* Mixed reality: Microsoft is a pioneer in the field of mixed reality, with a range of products and services that enable users to experience virtual and augmented reality.\\n* Devices: Microsoft produces a range of devices, including Surface laptops and tablets, Lumia smartphones, and HoloLens augmented reality headsets.\\n* Enterprise software: Microsoft offers a range of enterprise software solutions, including Dynamics 365 for business management, Dynamics CRM for customer relationship management, and Azure DevOps for software development and delivery.\\n* Online services: Microsoft offers a range of online services, including Bing search engine, MSN news and entertainment platform, and Skype communication platform.\\n* Education: Microsoft offers a range of educational software and resources, including Microsoft Office Specialist, Microsoft Certified Educator, and Minecraft: Education Edition.\\n* Healthcare: Microsoft offers a range of healthcare solutions, including Microsoft Healthcare, which provides a platform for healthcare providers to manage patient data and deliver personalized care.\\n\\nOverall, Microsoft is a diversified technology company with a wide range of products and services that cater to various industries and needs. The company has a strong track record of innovation and has played a significant role in shaping the technology industry over the past several decades.'"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm(\"Now write a summary for the company Microsoft.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "e7bef164",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "My apologies, here is the shortened version of the analysis for General Electric:\n",
      "\n",
      "GE is a multinational conglomerate that operates in a wide range of industries, including aviation, healthcare, and energy. The company has a long history of innovation and has been at the forefront of several technological advancements. GE has a strong brand and is known for its commitment to quality and reliability.\n",
      "\n",
      "However, the company has faced several challenges in recent years, including declining sales in some of its core businesses and increased competition from smaller, nimbler competitors. GE has also faced difficulties in its financial services arm, which has resulted in significant losses.\n",
      "\n",
      "Despite these challenges, GE has a diverse range of businesses and a strong cash flow position, which provides it with the ability to invest in new technologies and opportunities. The company has also been working to simplify its structure and reduce costs, which could help improve its profitability.\n",
      "\n",
      "Overall, while GE faces some challenges, it has a strong brand and a diverse range of businesses that provide it with opportunities for growth and profitability."
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nMy apologies, here is the shortened version of the analysis for General Electric:\\n\\nGE is a multinational conglomerate that operates in a wide range of industries, including aviation, healthcare, and energy. The company has a long history of innovation and has been at the forefront of several technological advancements. GE has a strong brand and is known for its commitment to quality and reliability.\\n\\nHowever, the company has faced several challenges in recent years, including declining sales in some of its core businesses and increased competition from smaller, nimbler competitors. GE has also faced difficulties in its financial services arm, which has resulted in significant losses.\\n\\nDespite these challenges, GE has a diverse range of businesses and a strong cash flow position, which provides it with the ability to invest in new technologies and opportunities. The company has also been working to simplify its structure and reduce costs, which could help improve its profitability.\\n\\nOverall, while GE faces some challenges, it has a strong brand and a diverse range of businesses that provide it with opportunities for growth and profitability.'"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm(\"This is too long, please follow the example you provided for General Electric.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4f07843e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting weaviate-client\n",
      "  Downloading weaviate_client-3.26.1-py3-none-any.whl.metadata (3.4 kB)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.30.0 in ./lib/python3.10/site-packages (from weaviate-client) (2.31.0)\n",
      "Collecting validators<1.0.0,>=0.21.2 (from weaviate-client)\n",
      "  Downloading validators-0.22.0-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting authlib<2.0.0,>=1.2.1 (from weaviate-client)\n",
      "  Downloading Authlib-1.3.0-py2.py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting cryptography (from authlib<2.0.0,>=1.2.1->weaviate-client)\n",
      "  Downloading cryptography-41.0.7-cp37-abi3-macosx_10_12_universal2.whl.metadata (5.2 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./lib/python3.10/site-packages (from requests<3.0.0,>=2.30.0->weaviate-client) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./lib/python3.10/site-packages (from requests<3.0.0,>=2.30.0->weaviate-client) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./lib/python3.10/site-packages (from requests<3.0.0,>=2.30.0->weaviate-client) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./lib/python3.10/site-packages (from requests<3.0.0,>=2.30.0->weaviate-client) (2023.11.17)\n",
      "Requirement already satisfied: cffi>=1.12 in ./lib/python3.10/site-packages (from cryptography->authlib<2.0.0,>=1.2.1->weaviate-client) (1.16.0)\n",
      "Requirement already satisfied: pycparser in ./lib/python3.10/site-packages (from cffi>=1.12->cryptography->authlib<2.0.0,>=1.2.1->weaviate-client) (2.21)\n",
      "Downloading weaviate_client-3.26.1-py3-none-any.whl (120 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m120.3/120.3 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading Authlib-1.3.0-py2.py3-none-any.whl (223 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m223.7/223.7 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading validators-0.22.0-py3-none-any.whl (26 kB)\n",
      "Downloading cryptography-41.0.7-cp37-abi3-macosx_10_12_universal2.whl (5.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.3/5.3 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: validators, cryptography, authlib, weaviate-client\n",
      "Successfully installed authlib-1.3.0 cryptography-41.0.7 validators-0.22.0 weaviate-client-3.26.1\n"
     ]
    }
   ],
   "source": [
    "!pip install weaviate-client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a2b7b33b-d056-427e-92e5-e1190d5924c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import weaviate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3fa32b0d-9a8b-403a-b601-fa5546ead17a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from weaviate.embedded import EmbeddedOptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32aa0b97-d1de-47d3-bd76-53245156c870",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llama",
   "language": "python",
   "name": "llama"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
